{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd9d359c",
   "metadata": {},
   "source": [
    "## Preflight Check\n",
    "\n",
    "If this fails with 401, regenerate OpenRouter key and restart kernel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16bc0d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL WORKING\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "load_dotenv(dotenv_path=\".env\", override=False)\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.environ[\"OPENROUTER_API_KEY\"].strip(),\n",
    "    default_headers={\n",
    "        \"HTTP-Referer\": \"http://localhost:8888\",\n",
    "        \"X-Title\": \"Dallas Agent Workshop\",\n",
    "    },\n",
    ")\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=os.getenv(\"OPENROUTER_MODEL\", \"arcee-ai/trinity-large-preview:free\"),\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Reply with exactly: MODEL WORKING\"}],\n",
    ")\n",
    "\n",
    "print(resp.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ef53b8",
   "metadata": {},
   "source": [
    "# Dallas AI — Hands-on Agent Building (LangGraph + OpenRouter)\n",
    "\n",
    "This notebook is the main workshop surface:\n",
    "- You will run the agent locally.\n",
    "- The model is accessed via OpenRouter.\n",
    "- The agent can generate Python code and execute it using a controlled tool.\n",
    "\n",
    "**Goal:** experience a real *plan → code → execute → fix* loop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8951d183",
   "metadata": {},
   "source": [
    "## 0) Setup\n",
    "\n",
    "1. Create a venv and install deps:\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "2. Copy `.env.example` to `.env` and set `OPENROUTER_API_KEY`.\n",
    "3. Restart kernel after editing `.env`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3898aa44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repr: 'e000c20e40'\n",
      "endswith newline? False\n",
      "has spaces? False\n",
      "len raw: 73 len strip: 73\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OPENROUTER_MODEL\"] = \"arcee-ai/trinity-large-preview:free\"\n",
    "\n",
    "k = os.environ[\"OPENROUTER_API_KEY\"]\n",
    "print(\"repr:\", repr(k[-10:]))\n",
    "print(\"endswith newline?\", k.endswith(\"\\n\"))\n",
    "print(\"has spaces?\", (\" \" in k))\n",
    "print(\"len raw:\", len(k), \"len strip:\", len(k.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0a3afab-4035-4279-871a-37ef4a0c687b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{\"data\":[{\"id\":\"qwen/qwen3.5-plus-02-15\",\"canonical_slug\":\"qwen/qwen3.5-plus-20260216\",\"hugging_face_id\":\"\",\"name\":\"Qwen: Qwen3.5 Plus 2026-02-15\",\"created\":1771229416,\"description\":\"The Qwen3.5 native vision-language series Plus models are built on a hybrid architecture that integrates linear atten\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiankunliu/workplace/dallas-agent-workshop-notebook/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os, requests\n",
    "headers = {\"Authorization\": f\"Bearer {os.environ['OPENROUTER_API_KEY'].strip()}\"}\n",
    "r = requests.get(\"https://openrouter.ai/api/v1/models\", headers=headers, timeout=20)\n",
    "print(r.status_code)\n",
    "print(r.text[:300])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ac4256",
   "metadata": {},
   "source": [
    "## 1) Sanity check: run the Python execution tool\n",
    "\n",
    "This runs locally with timeouts and basic restrictions. It is **not** a hardened sandbox.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6994df79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ok': True,\n",
       " 'stdout': 'hello from tool\\n6\\n',\n",
       " 'stderr': '',\n",
       " 'exit_code': 0,\n",
       " 'note': 'Execution policy: temporary working directory, time-limited, and blocks some risky imports/calls. This is NOT a hardened sandbox.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tools import run_python\n",
    "\n",
    "code = \"\"\"\n",
    "print('hello from tool')\n",
    "print(sum([1,2,3]))\n",
    "\"\"\"\n",
    "\n",
    "run_python(code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6314648a",
   "metadata": {},
   "source": [
    "## 2) Run a single agent task\n",
    "\n",
    "We will run one end-to-end task:\n",
    "- Planner proposes solution + code\n",
    "- Executor runs code\n",
    "- If fails, Fixer patches and retries (up to 3 attempts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e549b8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GENERATED CODE ===\n",
      "python\n",
      "# Compute Fibonacci(35) iteratively\n",
      "a, b = 0, 1\n",
      "for _ in range(35):\n",
      "    a, b = b, a + b\n",
      "print(a)\n",
      "======================\n",
      "=== GENERATED CODE ===\n",
      "# Compute Fibonacci(35) iteratively\n",
      "a, b = 0, 1\n",
      "for _ in range(35):\n",
      "    a, b = b, a + b\n",
      "print(a)\n",
      "======================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ok': True,\n",
       " 'stdout': '9227465\\n',\n",
       " 'stderr': '',\n",
       " 'exit_code': 0,\n",
       " 'note': 'Execution policy: temporary working directory, time-limited, and blocks some risky imports/calls. This is NOT a hardened sandbox.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agent_lib import run_task\n",
    "\n",
    "task = \"Write a Python function to compute Fibonacci(n) efficiently and print Fibonacci(35).\"\n",
    "result = run_task(task)\n",
    "\n",
    "result['last_run']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a672d9",
   "metadata": {},
   "source": [
    "## 3) Workshop exercises\n",
    "\n",
    "Try the tasks below. You can also author your own.\n",
    "Tip: keep tasks self-contained and offline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e25ceab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TASK: Parse this CSV string and compute the average of the 'latency_ms' column:\n",
      "\n",
      "ts,latency_ms\n",
      "1,120\n",
      "2,110\n",
      "3,130\n",
      "4,90\n",
      "\n",
      "=== GENERATED CODE ===\n",
      "python\n",
      "import csv\n",
      "from io import StringIO\n",
      "\n",
      "csv_string = \"\"\"ts,latency_ms\n",
      "1,120\n",
      "2,110\n",
      "3,130\n",
      "4,90\"\"\"\n",
      "\n",
      "f = StringIO(csv_string)\n",
      "reader = csv.DictReader(f)\n",
      "latencies = [int(row['latency_ms']) for row in reader]\n",
      "average = sum(latencies) / len(latencies)\n",
      "print(average)\n",
      "======================\n",
      "=== GENERATED CODE ===\n",
      "import csv\n",
      "from io import StringIO\n",
      "\n",
      "csv_string = \"\"\"ts,latency_ms\n",
      "1,120\n",
      "2,110\n",
      "3,130\n",
      "4,90\"\"\"\n",
      "\n",
      "f = StringIO(csv_string)\n",
      "reader = csv.DictReader(f)\n",
      "latencies = [int(row['latency_ms']) for row in reader]\n",
      "average = sum(latencies) / len(latencies)\n",
      "print(average)\n",
      "======================\n",
      "OK: True\n",
      "STDOUT:\n",
      " 112.5\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TASK: Implement rolling z-score anomaly score for this list and print the top 3 most anomalous points: [10,11,9,10,10,200,11,10,9,10]\n",
      "=== GENERATED CODE ===\n",
      "python\n",
      "import numpy as np\n",
      "\n",
      "data = [10, 11, 9, 10, 10, 200, 11, 10, 9, 10]\n",
      "window_size = 5\n",
      "z_scores = []\n",
      "\n",
      "for i in range(len(data)):\n",
      "    if i < window_size - 1:\n",
      "        z_scores.append(0)\n",
      "    else:\n",
      "        window = data[i - window_size + 1:i + 1]\n",
      "        mean = np.mean(window)\n",
      "        std = np.std(window)\n",
      "        if std == 0:\n",
      "            z = 0\n",
      "        else:\n",
      "            z = (data[i] - mean) / std\n",
      "        z_scores.append(z)\n",
      "\n",
      "anomalies = sorted(enumerate(z_scores), key=lambda x: abs(x[1]), reverse=True)[:3]\n",
      "print(anomalies)\n",
      "======================\n",
      "=== GENERATED CODE ===\n",
      "import numpy as np\n",
      "\n",
      "data = [10, 11, 9, 10, 10, 200, 11, 10, 9, 10]\n",
      "window_size = 5\n",
      "z_scores = []\n",
      "\n",
      "for i in range(len(data)):\n",
      "    if i < window_size - 1:\n",
      "        z_scores.append(0)\n",
      "    else:\n",
      "        window = data[i - window_size + 1:i + 1]\n",
      "        mean = np.mean(window)\n",
      "        std = np.std(window)\n",
      "        if std == 0:\n",
      "            z = 0\n",
      "        else:\n",
      "            z = (data[i] - mean) / std\n",
      "        z_scores.append(z)\n",
      "\n",
      "anomalies = sorted(enumerate(z_scores), key=lambda x: abs(x[1]), reverse=True)[:3]\n",
      "print(anomalies)\n",
      "======================\n",
      "=== GENERATED CODE ===\n",
      "data = [10, 11, 9, 10, 10, 200, 11, 10, 9, 10]\n",
      "window_size = 5\n",
      "z_scores = []\n",
      "\n",
      "for i in range(len(data)):\n",
      "    if i < window_size - 1:\n",
      "        z_scores.append(0)\n",
      "    else:\n",
      "        window = data[i - window_size + 1:i + 1]\n",
      "        mean = sum(window) / len(window)\n",
      "        variance = sum((x - mean) ** 2 for x in window) / len(window)\n",
      "        std = variance ** 0.5\n",
      "        if std == 0:\n",
      "            z = 0\n",
      "        else:\n",
      "            z = (data[i] - mean) / std\n",
      "        z_scores.append(z)\n",
      "\n",
      "anomalies = sorted(enumerate(z_scores), key=lambda x: abs(x[1]), reverse=True)[:3]\n",
      "print(anomalies)\n",
      "======================\n",
      "OK: True\n",
      "STDOUT:\n",
      " [(5, 1.9999307515191178), (8, -0.5131401270345105), (7, -0.5032872553862311)]\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TASK: Given a list of (user_id, event_time, event_type), compute per-user session counts (30-min gap) and print a dict.\n",
      "=== GENERATED CODE ===\n",
      "python\n",
      "events = [\n",
      "    (1, '2023-10-01 10:00:00', 'click'),\n",
      "    (1, '2023-10-01 10:20:00', 'view'),\n",
      "    (1, '2023-10-01 11:10:00', 'click'),\n",
      "    (2, '2023-10-01 10:00:00', 'click'),\n",
      "    (2, '2023-10-01 10:05:00', 'view'),\n",
      "    (2, '2023-10-01 10:40:00', 'click'),\n",
      "]\n",
      "\n",
      "from datetime import datetime\n",
      "\n",
      "# Convert event_time to datetime objects and sort by user_id and event_time\n",
      "events = [(user_id, datetime.strptime(event_time, '%Y-%m-%d %H:%M:%S'), event_type) for user_id, event_time, event_type in events]\n",
      "events.sort(key=lambda x: (x[0], x[1]))\n",
      "\n",
      "session_counts = {}\n",
      "current_user = None\n",
      "session_start = None\n",
      "session_count = 0\n",
      "\n",
      "for user_id, event_time, event_type in events:\n",
      "    if user_id != current_user:\n",
      "        if current_user is not None:\n",
      "            session_counts[current_user] = session_count\n",
      "        current_user = user_id\n",
      "        session_start = event_time\n",
      "        session_count = 1\n",
      "    else:\n",
      "        if (event_time - session_start).total_seconds() > 1800:  # 30 minutes = 1800 seconds\n",
      "            session_count += 1\n",
      "        session_start = event_time\n",
      "\n",
      "if current_user is not None:\n",
      "    session_counts[current_user] = session_count\n",
      "\n",
      "print(session_counts)\n",
      "======================\n",
      "=== GENERATED CODE ===\n",
      "from datetime import datetime\n",
      "\n",
      "events = [\n",
      "    (1, '2023-10-01 10:00:00', 'click'),\n",
      "    (1, '2023-10-01 10:20:00', 'view'),\n",
      "    (1, '2023-10-01 11:10:00', 'click'),\n",
      "    (2, '2023-10-01 10:00:00', 'click'),\n",
      "    (2, '2023-10-01 10:05:00', 'view'),\n",
      "    (2, '2023-10-01 10:40:00', 'click'),\n",
      "]\n",
      "\n",
      "# Convert event_time to datetime objects and sort by user_id and event_time\n",
      "events = [(user_id, datetime.strptime(event_time, '%Y-%m-%d %H:%M:%S'), event_type) for user_id, event_time, event_type in events]\n",
      "events.sort(key=lambda x: (x[0], x[1]))\n",
      "\n",
      "session_counts = {}\n",
      "current_user = None\n",
      "session_start = None\n",
      "session_count = 0\n",
      "\n",
      "for user_id, event_time, event_type in events:\n",
      "    if user_id != current_user:\n",
      "        if current_user is not None:\n",
      "            session_counts[current_user] = session_count\n",
      "        current_user = user_id\n",
      "        session_start = event_time\n",
      "        session_count = 1\n",
      "    else:\n",
      "        if (event_time - session_start).total_seconds() > 1800:  # 30 minutes = 1800 seconds\n",
      "            session_count += 1\n",
      "        session_start = event_time\n",
      "\n",
      "if current_user is not None:\n",
      "    session_counts[current_user] = session_count\n",
      "\n",
      "print(session_counts)\n",
      "======================\n",
      "OK: True\n",
      "STDOUT:\n",
      " {1: 2, 2: 2}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tasks = [\n",
    "    \"Parse this CSV string and compute the average of the 'latency_ms' column:\\n\\nts,latency_ms\\n1,120\\n2,110\\n3,130\\n4,90\\n\",\n",
    "    \"Implement rolling z-score anomaly score for this list and print the top 3 most anomalous points: [10,11,9,10,10,200,11,10,9,10]\",\n",
    "    \"Given a list of (user_id, event_time, event_type), compute per-user session counts (30-min gap) and print a dict.\"\n",
    "]\n",
    "\n",
    "for t in tasks:\n",
    "    print('\\n' + '='*80)\n",
    "    print('TASK:', t)\n",
    "    out = run_task(t)\n",
    "    print('OK:', out['last_run']['ok'])\n",
    "    print('STDOUT:\\n', out['last_run']['stdout'])\n",
    "    if not out['last_run']['ok']:\n",
    "        print('STDERR:\\n', out['last_run']['stderr'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1d53e9",
   "metadata": {},
   "source": [
    "## 3a) Advanced: tighten/loosen execution policy\n",
    "\n",
    "In `tools.py`, you can change:\n",
    "- timeout\n",
    "- banned patterns\n",
    "\n",
    "For meetup safety, keep it restrictive.\n"
   ]
  },
{
   "cell_type": "markdown",
   "id": "research_agent_intro",
   "metadata": {},
   "source": [
    "## 4) Applied Exercise: Research Agent\n",
    "\n",
    "Unlike the code-execution agent, this agent:\n",
    "- Plans multi-step searches\n",
    "- Gathers information from the web via Tavily\n",
    "- Synthesizes findings into a structured report\n",
    "\n",
    "**Use case:** competitive intelligence, market research, due diligence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "research_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "from research_agent import run_research\n",
    "\n",
    "question = \"What are the top 3 AI chip companies in 2024 and what's their competitive advantage?\"\n",
    "\n",
    "print(f\"RESEARCH QUESTION:\\n{question}\\n\")\n",
    "\n",
    "result = run_research(question)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL REPORT:\")\n",
    "print(\"=\"*60)\n",
    "print(result[\"report\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21269bc7",
   "metadata": {},
   "source": [
    "## 5) Optional: make it multi-agent\n",
    "\n",
    "You can extend `agent_lib.py` into multiple agents:\n",
    "- planner\n",
    "- coder\n",
    "- executor\n",
    "- verifier\n",
    "\n",
    "LangGraph makes these edges explicit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148e2e7a-cb87-4ccf-9f22-5c8e7380ad84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
